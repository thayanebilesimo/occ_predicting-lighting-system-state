{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_setup(filename, log_level):\n",
    "    logger = logging.getLogger(filename)\n",
    "    logger.setLevel(log_level)\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
    "                                  datefmt='%m-%d-%y %H:%M:%S')\n",
    "    fh = TimedRotatingFileHandler(os.path.join(\"logs\", filename + \".log\"), when='midnight')\n",
    "    fh.setFormatter(formatter)\n",
    "    sh = logging.StreamHandler(sys.stdout)\n",
    "    sh.setLevel(log_level)\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(sh)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "if os.path.isfile(\"logs/rf_antigo_para_recente.log\"):\n",
    "    os.remove(\"logs/rf_antigo_para_recente.log\")\n",
    "logger = log_setup(\"rf_antigo_para_recente\", logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../mai_2022_fev_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = list(data.columns)[:-1]\n",
    "logger.info(f\"features_names: {features_names}\")\n",
    "logger.info(f\"len(features_names): {len(features_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(dict(year=data.data_ano, month=data.data_mes, day=data.data_dia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day_range in [1, 7, 15, 30]:\n",
    "    data = original_data.copy()\n",
    "    logger.info(f\"day_range: {day_range}\")\n",
    "\n",
    "    min_date = datetime.strptime(str(data['date'].min())[:10], '%Y-%m-%d')\n",
    "    max_date = datetime.strptime(str(data['date'].max())[:10], '%Y-%m-%d')\n",
    "\n",
    "    logger.info(f\"min_date: {min_date}\")\n",
    "    logger.info(f\"max_date: {max_date}\")\n",
    "\n",
    "    initial_date_train = datetime.strptime(str(data['date'].min())[:10], '%Y-%m-%d')\n",
    "    final_date_train = initial_date_train + timedelta(days = day_range)\n",
    "\n",
    "    initial_date_test = final_date_train\n",
    "    final_date_test = initial_date_test + timedelta(days = day_range)\n",
    "\n",
    "    if final_date_train > max_date:\n",
    "        logger.info(\"A data final de treino é maior que a data máxima\")\n",
    "        break\n",
    "\n",
    "    if initial_date_test > max_date:\n",
    "        logger.info(\"A data inicial de teste é maior que a data máxima\")\n",
    "        break\n",
    "\n",
    "    logger.info(f\"initial_date_test: {initial_date_test}\")\n",
    "    logger.info(f\"final_date_test: {final_date_test}\")\n",
    "    logger.info(f\"initial_date_train: {initial_date_train}\")\n",
    "    logger.info(f\"final_date_train: {final_date_train}\")\n",
    "\n",
    "    logger.info(f\"original_data: {len(original_data)}\")\n",
    "\n",
    "    data_train = data.loc[(data['date'] >= initial_date_train) & (data['date'] < final_date_train)]\n",
    "    logger.info(f\"data_train: {len(data_train)}\")\n",
    "    data_test = data.loc[(data['date'] >= initial_date_test) & (data['date'] < final_date_test)]\n",
    "    logger.info(f\"data_test: {len(data_test)}\")\n",
    "\n",
    "    logger.info(f\"min_date_train: {data_train['date'].min()}\")\n",
    "    logger.info(f\"max_date_train: {data_train['date'].max()}\")\n",
    "    logger.info(f\"min_date_test: {data_test['date'].min()}\")\n",
    "    logger.info(f\"max_date_test: {data_test['date'].max()}\")\n",
    "\n",
    "    logger.info(f\"Distribuição de classes - Treino: {data_train['output'].value_counts()}\")\n",
    "    logger.info(f\"Distribuição de classes - Teste: {data_test['output'].value_counts()}\")\n",
    "\n",
    "    X_train = data_train[features_names]\n",
    "    logger.info(f\"X_train.shape: {X_train.shape}\")\n",
    "\n",
    "    X_train = X_train.values.tolist()\n",
    "    y_train = data_train['output'].values.tolist()\n",
    "    logger.info(f\"Classes de treino: {np.unique(y_train)}\")\n",
    "\n",
    "    X_test = data_test[features_names]\n",
    "    logger.info(f\"X_test.shape: {X_test.shape}\")\n",
    "\n",
    "    X_test = X_test.values.tolist()\n",
    "    y_test = data_test['output'].values.tolist()\n",
    "    logger.info(f\"Classes de teste: {np.unique(y_test)}\")\n",
    "\n",
    "    # Train-Test\n",
    "    logger.info(\"\\n-- Train/Test --\")\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=SEED)\n",
    "    try:\n",
    "        clf.fit(X_train, y_train)\n",
    "    except Exception as error:\n",
    "        logger.info(f\"Erro: {error}\")\n",
    "        continue\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    logger.info('Precision: %.3f' % precision_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('Recall: %.3f' % recall_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('F1: %.3f' % f1_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "    logger.info(f\"cm: {cm}\")\n",
    "\n",
    "    # Reescalando os dados\n",
    "    logger.info(\"\\n-- Train/Test with data scaling --\")\n",
    "    scaler_train = StandardScaler()\n",
    "    scaler_train.fit(X_train)\n",
    "    X_train_scaled = scaler_train.transform(X_train)\n",
    "\n",
    "    X_test_scaled = scaler_train.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(max_depth=3, random_state=SEED)\n",
    "    try:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "    except Exception as error:\n",
    "        logger.info(f\"Erro: {error}\")\n",
    "        continue\n",
    "\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "    logger.info('Precision: %.3f' % precision_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('Recall: %.3f' % recall_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('F1: %.3f' % f1_score(y_test, y_pred, average='weighted'))\n",
    "    logger.info('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "    logger.info(f\"cm: {cm}\")\n",
    "\n",
    "    logger.info(\"\\n ============================================================================= \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_prime",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
